{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path1 = 'obtrain-ml.csv'\n",
    "\n",
    "df = pd.read_csv(path1, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>550</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.345081</td>\n",
       "      <td>0.746197</td>\n",
       "      <td>-1.090600</td>\n",
       "      <td>-1.080283</td>\n",
       "      <td>-0.271744</td>\n",
       "      <td>0.071893</td>\n",
       "      <td>-0.750719</td>\n",
       "      <td>1.320688</td>\n",
       "      <td>0.695390</td>\n",
       "      <td>1.163406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432794</td>\n",
       "      <td>-0.343324</td>\n",
       "      <td>-1.237080</td>\n",
       "      <td>0.392683</td>\n",
       "      <td>-1.937201</td>\n",
       "      <td>1.273496</td>\n",
       "      <td>0.471206</td>\n",
       "      <td>0.088425</td>\n",
       "      <td>-0.754906</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.238198</td>\n",
       "      <td>-0.990755</td>\n",
       "      <td>0.471342</td>\n",
       "      <td>-0.101829</td>\n",
       "      <td>-1.129983</td>\n",
       "      <td>0.341522</td>\n",
       "      <td>1.189618</td>\n",
       "      <td>-0.720331</td>\n",
       "      <td>0.104180</td>\n",
       "      <td>-1.092291</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.290025</td>\n",
       "      <td>0.139505</td>\n",
       "      <td>0.117134</td>\n",
       "      <td>-0.186936</td>\n",
       "      <td>0.408618</td>\n",
       "      <td>0.237257</td>\n",
       "      <td>-1.110670</td>\n",
       "      <td>-0.645378</td>\n",
       "      <td>1.779565</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.008384</td>\n",
       "      <td>0.834482</td>\n",
       "      <td>0.726280</td>\n",
       "      <td>-1.889651</td>\n",
       "      <td>0.927735</td>\n",
       "      <td>-0.167712</td>\n",
       "      <td>0.570338</td>\n",
       "      <td>0.808293</td>\n",
       "      <td>-1.187723</td>\n",
       "      <td>-0.093282</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.068939</td>\n",
       "      <td>-1.592181</td>\n",
       "      <td>-0.709196</td>\n",
       "      <td>0.754166</td>\n",
       "      <td>-0.060812</td>\n",
       "      <td>-0.646838</td>\n",
       "      <td>-0.774647</td>\n",
       "      <td>0.161045</td>\n",
       "      <td>-1.289014</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.082521</td>\n",
       "      <td>0.900501</td>\n",
       "      <td>1.673648</td>\n",
       "      <td>0.935160</td>\n",
       "      <td>1.558300</td>\n",
       "      <td>-0.406216</td>\n",
       "      <td>-0.735869</td>\n",
       "      <td>0.540115</td>\n",
       "      <td>-0.494145</td>\n",
       "      <td>-0.496822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453064</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>1.205144</td>\n",
       "      <td>-1.941207</td>\n",
       "      <td>0.246593</td>\n",
       "      <td>0.710245</td>\n",
       "      <td>1.027464</td>\n",
       "      <td>0.483457</td>\n",
       "      <td>1.000004</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.134288</td>\n",
       "      <td>-0.561238</td>\n",
       "      <td>-1.293037</td>\n",
       "      <td>-0.703646</td>\n",
       "      <td>1.918425</td>\n",
       "      <td>-1.160573</td>\n",
       "      <td>-0.106683</td>\n",
       "      <td>0.546631</td>\n",
       "      <td>-0.006137</td>\n",
       "      <td>0.632034</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.686108</td>\n",
       "      <td>0.544527</td>\n",
       "      <td>0.886340</td>\n",
       "      <td>-0.885839</td>\n",
       "      <td>0.574833</td>\n",
       "      <td>-1.298381</td>\n",
       "      <td>0.814288</td>\n",
       "      <td>-0.834902</td>\n",
       "      <td>0.195764</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 560 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.345081  0.746197 -1.090600 -1.080283 -0.271744  0.071893 -0.750719   \n",
       "1 -1.238198 -0.990755  0.471342 -0.101829 -1.129983  0.341522  1.189618   \n",
       "2 -0.008384  0.834482  0.726280 -1.889651  0.927735 -0.167712  0.570338   \n",
       "3 -0.082521  0.900501  1.673648  0.935160  1.558300 -0.406216 -0.735869   \n",
       "4 -2.134288 -0.561238 -1.293037 -0.703646  1.918425 -1.160573 -0.106683   \n",
       "\n",
       "        7         8         9   ...        550       551       552       553  \\\n",
       "0  1.320688  0.695390  1.163406 ...   0.432794 -0.343324 -1.237080  0.392683   \n",
       "1 -0.720331  0.104180 -1.092291 ...  -1.290025  0.139505  0.117134 -0.186936   \n",
       "2  0.808293 -1.187723 -0.093282 ...  -1.068939 -1.592181 -0.709196  0.754166   \n",
       "3  0.540115 -0.494145 -0.496822 ...   0.453064  0.929381  1.205144 -1.941207   \n",
       "4  0.546631 -0.006137  0.632034 ...  -2.686108  0.544527  0.886340 -0.885839   \n",
       "\n",
       "        554       555       556       557       558  559  \n",
       "0 -1.937201  1.273496  0.471206  0.088425 -0.754906 -1.0  \n",
       "1  0.408618  0.237257 -1.110670 -0.645378  1.779565 -1.0  \n",
       "2 -0.060812 -0.646838 -0.774647  0.161045 -1.289014 -1.0  \n",
       "3  0.246593  0.710245  1.027464  0.483457  1.000004  1.0  \n",
       "4  0.574833 -1.298381  0.814288 -0.834902  0.195764  1.0  \n",
       "\n",
       "[5 rows x 560 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Columns: 560 entries, 0 to 559\n",
      "dtypes: float64(560)\n",
      "memory usage: 8.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>550</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.533041e-16</td>\n",
       "      <td>2.373102e-16</td>\n",
       "      <td>3.731460e-16</td>\n",
       "      <td>5.121459e-16</td>\n",
       "      <td>-2.249312e-16</td>\n",
       "      <td>-5.644374e-16</td>\n",
       "      <td>-1.430522e-15</td>\n",
       "      <td>1.479372e-16</td>\n",
       "      <td>1.797035e-16</td>\n",
       "      <td>-3.349959e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.074824e-16</td>\n",
       "      <td>4.851675e-17</td>\n",
       "      <td>1.095790e-15</td>\n",
       "      <td>6.250556e-15</td>\n",
       "      <td>3.201051e-16</td>\n",
       "      <td>5.143663e-15</td>\n",
       "      <td>7.799317e-18</td>\n",
       "      <td>-9.864332e-16</td>\n",
       "      <td>-9.859336e-16</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.000250e+00</td>\n",
       "      <td>1.00025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.806609e+00</td>\n",
       "      <td>-3.249674e+00</td>\n",
       "      <td>-3.340611e+00</td>\n",
       "      <td>-3.298440e+00</td>\n",
       "      <td>-3.228107e+00</td>\n",
       "      <td>-3.259287e+00</td>\n",
       "      <td>-3.237158e+00</td>\n",
       "      <td>-3.518765e+00</td>\n",
       "      <td>-3.117747e+00</td>\n",
       "      <td>-3.669559e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.123012e+00</td>\n",
       "      <td>-3.089802e+00</td>\n",
       "      <td>-3.754656e+00</td>\n",
       "      <td>-3.578335e+00</td>\n",
       "      <td>-3.839075e+00</td>\n",
       "      <td>-3.471544e+00</td>\n",
       "      <td>-3.735818e+00</td>\n",
       "      <td>-3.734729e+00</td>\n",
       "      <td>-4.071743e+00</td>\n",
       "      <td>-1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.518120e-01</td>\n",
       "      <td>-8.620804e-01</td>\n",
       "      <td>-6.931272e-01</td>\n",
       "      <td>-6.918625e-01</td>\n",
       "      <td>-6.489926e-01</td>\n",
       "      <td>-6.539326e-01</td>\n",
       "      <td>-6.638078e-01</td>\n",
       "      <td>-7.164303e-01</td>\n",
       "      <td>-6.833506e-01</td>\n",
       "      <td>-6.996555e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.071954e-01</td>\n",
       "      <td>-6.765307e-01</td>\n",
       "      <td>-6.444703e-01</td>\n",
       "      <td>-6.529039e-01</td>\n",
       "      <td>-6.870561e-01</td>\n",
       "      <td>-6.731509e-01</td>\n",
       "      <td>-6.744861e-01</td>\n",
       "      <td>-6.744321e-01</td>\n",
       "      <td>-6.624165e-01</td>\n",
       "      <td>-1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.110822e-02</td>\n",
       "      <td>-7.019288e-03</td>\n",
       "      <td>-2.689188e-04</td>\n",
       "      <td>-2.197787e-02</td>\n",
       "      <td>-2.821030e-03</td>\n",
       "      <td>-1.339113e-02</td>\n",
       "      <td>2.389254e-02</td>\n",
       "      <td>3.500354e-02</td>\n",
       "      <td>1.872041e-02</td>\n",
       "      <td>-2.242355e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.640873e-02</td>\n",
       "      <td>-1.159443e-02</td>\n",
       "      <td>3.245307e-02</td>\n",
       "      <td>-5.806578e-02</td>\n",
       "      <td>-5.655842e-02</td>\n",
       "      <td>9.680798e-03</td>\n",
       "      <td>3.983293e-02</td>\n",
       "      <td>1.050333e-02</td>\n",
       "      <td>9.302599e-03</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.537779e-01</td>\n",
       "      <td>8.554428e-01</td>\n",
       "      <td>7.047071e-01</td>\n",
       "      <td>6.453907e-01</td>\n",
       "      <td>6.784400e-01</td>\n",
       "      <td>6.430344e-01</td>\n",
       "      <td>6.495657e-01</td>\n",
       "      <td>5.598357e-01</td>\n",
       "      <td>6.493064e-01</td>\n",
       "      <td>6.732397e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.933908e-01</td>\n",
       "      <td>6.625549e-01</td>\n",
       "      <td>6.595602e-01</td>\n",
       "      <td>6.322097e-01</td>\n",
       "      <td>7.105999e-01</td>\n",
       "      <td>6.671100e-01</td>\n",
       "      <td>6.825393e-01</td>\n",
       "      <td>6.653655e-01</td>\n",
       "      <td>6.653531e-01</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.965983e+00</td>\n",
       "      <td>3.193342e+00</td>\n",
       "      <td>2.940053e+00</td>\n",
       "      <td>2.732206e+00</td>\n",
       "      <td>3.611380e+00</td>\n",
       "      <td>3.427170e+00</td>\n",
       "      <td>3.158721e+00</td>\n",
       "      <td>3.343066e+00</td>\n",
       "      <td>3.233024e+00</td>\n",
       "      <td>3.241649e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.287154e+00</td>\n",
       "      <td>3.635809e+00</td>\n",
       "      <td>3.316442e+00</td>\n",
       "      <td>3.455745e+00</td>\n",
       "      <td>4.175236e+00</td>\n",
       "      <td>3.360887e+00</td>\n",
       "      <td>3.527163e+00</td>\n",
       "      <td>4.544100e+00</td>\n",
       "      <td>3.773016e+00</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 560 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  2.000000e+03  2.000000e+03  2.000000e+03  2.000000e+03  2.000000e+03   \n",
       "mean  -4.533041e-16  2.373102e-16  3.731460e-16  5.121459e-16 -2.249312e-16   \n",
       "std    1.000250e+00  1.000250e+00  1.000250e+00  1.000250e+00  1.000250e+00   \n",
       "min   -3.806609e+00 -3.249674e+00 -3.340611e+00 -3.298440e+00 -3.228107e+00   \n",
       "25%   -6.518120e-01 -8.620804e-01 -6.931272e-01 -6.918625e-01 -6.489926e-01   \n",
       "50%   -1.110822e-02 -7.019288e-03 -2.689188e-04 -2.197787e-02 -2.821030e-03   \n",
       "75%    6.537779e-01  8.554428e-01  7.047071e-01  6.453907e-01  6.784400e-01   \n",
       "max    2.965983e+00  3.193342e+00  2.940053e+00  2.732206e+00  3.611380e+00   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  2.000000e+03  2.000000e+03  2.000000e+03  2.000000e+03  2.000000e+03   \n",
       "mean  -5.644374e-16 -1.430522e-15  1.479372e-16  1.797035e-16 -3.349959e-16   \n",
       "std    1.000250e+00  1.000250e+00  1.000250e+00  1.000250e+00  1.000250e+00   \n",
       "min   -3.259287e+00 -3.237158e+00 -3.518765e+00 -3.117747e+00 -3.669559e+00   \n",
       "25%   -6.539326e-01 -6.638078e-01 -7.164303e-01 -6.833506e-01 -6.996555e-01   \n",
       "50%   -1.339113e-02  2.389254e-02  3.500354e-02  1.872041e-02 -2.242355e-03   \n",
       "75%    6.430344e-01  6.495657e-01  5.598357e-01  6.493064e-01  6.732397e-01   \n",
       "max    3.427170e+00  3.158721e+00  3.343066e+00  3.233024e+00  3.241649e+00   \n",
       "\n",
       "          ...               550           551           552           553  \\\n",
       "count     ...      2.000000e+03  2.000000e+03  2.000000e+03  2.000000e+03   \n",
       "mean      ...     -9.074824e-16  4.851675e-17  1.095790e-15  6.250556e-15   \n",
       "std       ...      1.000250e+00  1.000250e+00  1.000250e+00  1.000250e+00   \n",
       "min       ...     -4.123012e+00 -3.089802e+00 -3.754656e+00 -3.578335e+00   \n",
       "25%       ...     -6.071954e-01 -6.765307e-01 -6.444703e-01 -6.529039e-01   \n",
       "50%       ...      2.640873e-02 -1.159443e-02  3.245307e-02 -5.806578e-02   \n",
       "75%       ...      6.933908e-01  6.625549e-01  6.595602e-01  6.322097e-01   \n",
       "max       ...      3.287154e+00  3.635809e+00  3.316442e+00  3.455745e+00   \n",
       "\n",
       "                554           555           556           557           558  \\\n",
       "count  2.000000e+03  2.000000e+03  2.000000e+03  2.000000e+03  2.000000e+03   \n",
       "mean   3.201051e-16  5.143663e-15  7.799317e-18 -9.864332e-16 -9.859336e-16   \n",
       "std    1.000250e+00  1.000250e+00  1.000250e+00  1.000250e+00  1.000250e+00   \n",
       "min   -3.839075e+00 -3.471544e+00 -3.735818e+00 -3.734729e+00 -4.071743e+00   \n",
       "25%   -6.870561e-01 -6.731509e-01 -6.744861e-01 -6.744321e-01 -6.624165e-01   \n",
       "50%   -5.655842e-02  9.680798e-03  3.983293e-02  1.050333e-02  9.302599e-03   \n",
       "75%    7.105999e-01  6.671100e-01  6.825393e-01  6.653655e-01  6.653531e-01   \n",
       "max    4.175236e+00  3.360887e+00  3.527163e+00  4.544100e+00  3.773016e+00   \n",
       "\n",
       "              559  \n",
       "count  2000.00000  \n",
       "mean      0.00000  \n",
       "std       1.00025  \n",
       "min      -1.00000  \n",
       "25%      -1.00000  \n",
       "50%       0.00000  \n",
       "75%       1.00000  \n",
       "max       1.00000  \n",
       "\n",
       "[8 rows x 560 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "The data is split into train and test datasets in a stratified fashion using the target label. The training dataset includes 75% of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df[559]=df[559].replace(-1, 0) #replace -1 with 0 for binary classification (0,1)\n",
    "y = df[559]\n",
    "X = df.drop(559,axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 15) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "The number of missing values in each column of the training and test datasets are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any null value in the training dataset?   False\n",
      "Is there any null value in the test dataset?       False\n"
     ]
    }
   ],
   "source": [
    "print ('Is there any null value in the training dataset?   %s' % (X_train.isnull().any()).any())\n",
    "print ('Is there any null value in the test dataset?       %s' % (X_test.isnull().any()).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEeCAYAAABrB7XiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/j+tVFXpq5PN0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111d01048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_context('notebook',font_scale=1.5)\n",
    "labels =['Postive','Negative']\n",
    "colors = ['yellowgreen', 'lightcoral']\n",
    "explode = (0, 0.1)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.pie(y_train.value_counts(),labels=labels,colors=colors,explode=explode, shadow=True, startangle=90, autopct='%.2f');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_features: []\n",
      "float_features: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558]\n",
      "bool_features: []\n",
      "categorical_features: []\n"
     ]
    }
   ],
   "source": [
    "#count the numbers of int64, float64, bool or object/string features\n",
    "train = X\n",
    "int_features = train.select_dtypes(include = ['int64']).columns.values\n",
    "float_features = train.select_dtypes(include = ['float64']).columns.values\n",
    "bool_features= train.select_dtypes(include = ['bool']).columns.values\n",
    "categorical_features = train.select_dtypes(include = ['object']).columns.values\n",
    "print('int_features:', int_features) #, 'count of int_features:'count(int_features)\n",
    "print('float_features:', float_features)\n",
    "print('bool_features:', bool_features)\n",
    "print('categorical_features:', categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11c60dcc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAIYCAYAAACL7i3DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiqGjs7REREVNXY2SEiIqKq9n9MUkXx6+mSbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c321fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = train.corr()\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "\n",
    "plt.title('Pearson Correlation of All Features', y=1.05, size=20)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=0.1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "# Create an XGBoost-compatible metric from Gini\n",
    "\n",
    "def gini_coefficient(preds,dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'gini', -gini_normalized(y,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Anaconda/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import precision_score, accuracy_score, f1_score, roc_auc_score\n",
    "import xgboost as xgb\n",
    "#cross_validation.py:41: DeprecationWarning is due to the xgboost package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>gini</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.069344</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.403141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Extra Tree</td>\n",
       "      <td>0.077184</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.507726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.051136</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.524793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.09472</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.553971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.11504</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.561475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.122944</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.563786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.150816</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.579592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.182272</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.599190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.176448</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.342592</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.665272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.486144</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.746988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoostClassifier</td>\n",
       "      <td>0.549728</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.771717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       clf      gini precision accuracy        f1\n",
       "2     KNeighborsClassifier  0.069344     0.308    0.544  0.403141\n",
       "11              Extra Tree  0.077184      0.46    0.554  0.507726\n",
       "6            SGDClassifier  0.051136     0.508     0.54  0.524793\n",
       "5                LinearSVC   0.09472     0.544    0.562  0.553971\n",
       "0       LogisticRegression   0.11504     0.548    0.572  0.561475\n",
       "4               Perceptron  0.122944     0.548    0.576  0.563786\n",
       "3               GaussianNB  0.150816     0.568    0.588  0.579592\n",
       "10                AdaBoost  0.182272     0.592    0.604  0.599190\n",
       "1                      SVC  0.176448     0.604    0.604  0.604000\n",
       "8   RandomForestClassifier  0.342592     0.636     0.68  0.665272\n",
       "7   DecisionTreeClassifier  0.486144     0.744    0.748  0.746988\n",
       "9        XGBoostClassifier  0.549728     0.764    0.774  0.771717"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try simple models 101 class_weight='balanced' is satisfied\n",
    "clfs = {'LogisticRegression':LogisticRegression(),\n",
    "        'SVC': SVC(),\n",
    "        'KNeighborsClassifier': KNeighborsClassifier(n_neighbors = 2),\n",
    "        'GaussianNB': GaussianNB(), \n",
    "        'Perceptron': Perceptron(max_iter=1000), \n",
    "        'LinearSVC': LinearSVC(), \n",
    "        'SGDClassifier': SGDClassifier(max_iter=1000), \n",
    "        'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "        'RandomForestClassifier': RandomForestClassifier(n_estimators=100),\n",
    "        'XGBoostClassifier': xgb.XGBClassifier(max_depth=5, n_estimators=500, learning_rate=0.05),\n",
    "        'AdaBoost': AdaBoostClassifier(), \n",
    "        'Extra Tree': ExtraTreesClassifier()\n",
    "       }\n",
    "\n",
    "res2 = []\n",
    "for name, clf in clfs.items():\n",
    "    clf.fit(X_train,y_train)\n",
    "    ypred = clf.predict(X_test)\n",
    "    gini_ = gini_normalized(y_test,ypred)\n",
    "    precision_ = precision_score(ypred, y_test)\n",
    "    accuracy_ = accuracy_score(ypred,y_test)\n",
    "    f1_ = f1_score(ypred,y_test)\n",
    "    res2.append([name, gini_, precision_, accuracy_, f1_])\n",
    "\n",
    "res2_score = pd.DataFrame(np.array(res2).reshape(12,5), columns = ['clf', 'gini', 'precision', 'accuracy', 'f1'])\n",
    "res2_score['f1'] = res2_score['f1'].astype(float)\n",
    "res2_score.sort_values('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Tree classifier: gini = 0.6500, precision = 0.8160, accuracy = 0.8160, f1 score = 0.8160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>gini</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.069344</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.403141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Extra Tree</td>\n",
       "      <td>0.077184</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.507726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.051136</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.524793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.09472</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.553971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.11504</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.561475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.122944</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.563786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.150816</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.579592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.182272</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.599190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.176448</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.342592</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.665272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.486144</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.746988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoostClassifier</td>\n",
       "      <td>0.549728</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.771717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xgb2</td>\n",
       "      <td>0.649952</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.816000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       clf      gini precision accuracy        f1\n",
       "2     KNeighborsClassifier  0.069344     0.308    0.544  0.403141\n",
       "11              Extra Tree  0.077184      0.46    0.554  0.507726\n",
       "6            SGDClassifier  0.051136     0.508     0.54  0.524793\n",
       "5                LinearSVC   0.09472     0.544    0.562  0.553971\n",
       "0       LogisticRegression   0.11504     0.548    0.572  0.561475\n",
       "4               Perceptron  0.122944     0.548    0.576  0.563786\n",
       "3               GaussianNB  0.150816     0.568    0.588  0.579592\n",
       "10                AdaBoost  0.182272     0.592    0.604  0.599190\n",
       "1                      SVC  0.176448     0.604    0.604  0.604000\n",
       "8   RandomForestClassifier  0.342592     0.636     0.68  0.665272\n",
       "7   DecisionTreeClassifier  0.486144     0.744    0.748  0.746988\n",
       "9        XGBoostClassifier  0.549728     0.764    0.774  0.771717\n",
       "12                    xgb2  0.649952     0.816    0.816  0.816000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb2=xgb.XGBClassifier(max_depth=6, n_estimators=1500, learning_rate=0.01, nthread=4)\n",
    "\n",
    "xgb2.fit(X_train,y_train)\n",
    "ypred = xgb2.predict(X_test)\n",
    "gini_ = gini_normalized(y_test,ypred)\n",
    "precision_ = precision_score(ypred, y_test)\n",
    "accuracy_ = accuracy_score(ypred,y_test)\n",
    "f1_ = f1_score(ypred,y_test)\n",
    "df2 = pd.DataFrame([['xgb2', gini_, precision_, accuracy_, f1_]], columns=['clf', 'gini', 'precision', 'accuracy', 'f1'])\n",
    "res2_score = res2_score.append(df2, ignore_index=True)\n",
    "res2_score.sort_values('f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB parameters: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "def XGB_CV(\n",
    "          max_depth,\n",
    "          gamma,\n",
    "          min_child_weight,\n",
    "          max_delta_step,\n",
    "          subsample,\n",
    "          colsample_bytree\n",
    "         ):\n",
    "\n",
    "    global AUCbest\n",
    "    global ITERbest\n",
    "#\n",
    "# Define all XGboost parameters\n",
    "#\n",
    "\n",
    "    paramt = {\n",
    "              'booster' : 'gbtree',\n",
    "              'max_depth' : int(max_depth),\n",
    "              'gamma' : gamma,\n",
    "              'learning_rate' : 0.05,\n",
    "              'objective' : 'binary:logistic',\n",
    "              'nthread' : 4,\n",
    "              'silent' : True,\n",
    "              'eval_metric': 'auc',\n",
    "              'subsample' : max(min(subsample, 1), 0),\n",
    "              'colsample_bytree' : max(min(colsample_bytree, 1), 0),\n",
    "              'min_child_weight' : min_child_weight,\n",
    "              'max_delta_step' : int(max_delta_step),\n",
    "              'seed' : 42\n",
    "              }\n",
    "\n",
    "    folds = 5\n",
    "    cv_score = 0\n",
    "\n",
    "    print(\"\\n Search parameters (%d-fold validation):\\n %s\" % (folds, paramt), file=log_file )\n",
    "    log_file.flush()\n",
    "\n",
    "    xgbc = xgb.cv(\n",
    "                    paramt,\n",
    "                    dtrain,\n",
    "                    num_boost_round = 2000,\n",
    "                    stratified = True,\n",
    "                    nfold = folds,\n",
    "#                    verbose_eval = 10,\n",
    "                    early_stopping_rounds = 100,\n",
    "                    metrics = 'auc',\n",
    "                    show_stdv = True\n",
    "               )\n",
    "    \n",
    "    val_score = xgbc['test-auc-mean'].iloc[-1]\n",
    "    train_score = xgbc['train-auc-mean'].iloc[-1]\n",
    "    print(' Stopped after %d iterations with train-auc = %f val-auc = %f ( diff = %f ) train-gini = %f val-gini = %f' % ( len(xgbc), train_score, val_score, (train_score - val_score), (train_score*2-1),\n",
    "(val_score*2-1)))\n",
    "    if ( val_score > AUCbest ):\n",
    "        AUCbest = val_score\n",
    "        ITERbest = len(xgbc)\n",
    "\n",
    "    return (val_score*2) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XGB_BO = BayesianOptimization(XGB_CV, {\n",
    "                                     'max_depth': (3, 12),\n",
    "                                     'gamma': (0.001, 20.0),\n",
    "                                     'min_child_weight': (0, 20),\n",
    "                                     'max_delta_step': (0, 10),\n",
    "                                     'subsample': (0.4, 1.0),\n",
    "                                     'colsample_bytree' :(0.4, 1.0)\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XGB_BO.explore({\n",
    "              'max_depth':            [3, 8, 3, 8, 8, 3, 8, 3],\n",
    "              'gamma':                [0.5, 8, 0.2, 9, 0.5, 8, 0.2, 9],\n",
    "              'min_child_weight':     [0.2, 0.2, 0.2, 0.2, 12, 12, 12, 12],\n",
    "              'max_delta_step':       [1, 2, 2, 1, 2, 1, 1, 2],\n",
    "              'subsample':            [0.6, 0.8, 0.6, 0.8, 0.6, 0.8, 0.6, 0.8],\n",
    "              'colsample_bytree':     [0.6, 0.8, 0.6, 0.8, 0.6, 0.8, 0.6, 0.8],\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   subsample | \n",
      " Stopped after 37 iterations with train-auc = 0.899687 val-auc = 0.798205 ( diff = 0.101482 ) train-gini = 0.799374 val-gini = 0.596410\n",
      "    1 | 00m17s | \u001b[35m   0.59641\u001b[0m | \u001b[32m            0.6000\u001b[0m | \u001b[32m   0.5000\u001b[0m | \u001b[32m          1.0000\u001b[0m | \u001b[32m     3.0000\u001b[0m | \u001b[32m            0.2000\u001b[0m | \u001b[32m     0.6000\u001b[0m | \n",
      " Stopped after 32 iterations with train-auc = 0.984375 val-auc = 0.894720 ( diff = 0.089655 ) train-gini = 0.968751 val-gini = 0.789440\n",
      "    2 | 01m04s | \u001b[35m   0.78944\u001b[0m | \u001b[32m            0.8000\u001b[0m | \u001b[32m   8.0000\u001b[0m | \u001b[32m          2.0000\u001b[0m | \u001b[32m     8.0000\u001b[0m | \u001b[32m            0.2000\u001b[0m | \u001b[32m     0.8000\u001b[0m | \n",
      " Stopped after 37 iterations with train-auc = 0.906475 val-auc = 0.793060 ( diff = 0.113415 ) train-gini = 0.812951 val-gini = 0.586120\n",
      "    3 | 00m17s |    0.58612 |             0.6000 |    0.2000 |           2.0000 |      3.0000 |             0.2000 |      0.6000 | \n",
      " Stopped after 78 iterations with train-auc = 0.985155 val-auc = 0.891470 ( diff = 0.093685 ) train-gini = 0.970309 val-gini = 0.782940\n",
      "    4 | 01m27s |    0.78294 |             0.8000 |    9.0000 |           1.0000 |      8.0000 |             0.2000 |      0.8000 | \n",
      " Stopped after 36 iterations with train-auc = 0.960101 val-auc = 0.827890 ( diff = 0.132211 ) train-gini = 0.920201 val-gini = 0.655780\n",
      "    5 | 00m26s |    0.65578 |             0.6000 |    0.5000 |           2.0000 |      8.0000 |            12.0000 |      0.6000 | \n",
      " Stopped after 94 iterations with train-auc = 0.956654 val-auc = 0.809950 ( diff = 0.146704 ) train-gini = 0.913308 val-gini = 0.619900\n",
      "    6 | 00m34s |    0.61990 |             0.8000 |    8.0000 |           1.0000 |      3.0000 |            12.0000 |      0.8000 | \n",
      " Stopped after 37 iterations with train-auc = 0.950694 val-auc = 0.829090 ( diff = 0.121604 ) train-gini = 0.901387 val-gini = 0.658180\n",
      "    7 | 00m28s |    0.65818 |             0.6000 |    0.2000 |           1.0000 |      8.0000 |            12.0000 |      0.6000 | \n",
      " Stopped after 78 iterations with train-auc = 0.943819 val-auc = 0.807420 ( diff = 0.136399 ) train-gini = 0.887637 val-gini = 0.614840\n",
      "    8 | 00m32s |    0.61484 |             0.8000 |    9.0000 |           2.0000 |      3.0000 |            12.0000 |      0.8000 | \n",
      " Stopped after 22 iterations with train-auc = 0.823947 val-auc = 0.757835 ( diff = 0.066112 ) train-gini = 0.647894 val-gini = 0.515670\n",
      "    9 | 00m18s |    0.51567 |             0.7732 |   10.5110 |           3.0022 |     11.7961 |            19.8156 |      0.4367 | \n",
      " Stopped after 27 iterations with train-auc = 0.978778 val-auc = 0.878165 ( diff = 0.100613 ) train-gini = 0.957557 val-gini = 0.756330\n",
      "   10 | 00m49s |    0.75633 |             0.8852 |    1.7633 |           3.8781 |      8.7341 |             8.0716 |      0.7503 | \n",
      " Stopped after 18 iterations with train-auc = 0.838770 val-auc = 0.757830 ( diff = 0.080940 ) train-gini = 0.677540 val-gini = 0.515660\n",
      "   11 | 00m09s |    0.51566 |             0.4098 |    5.7755 |           9.9798 |      8.8962 |            17.1301 |      0.4265 | \n",
      " Stopped after 205 iterations with train-auc = 0.970693 val-auc = 0.893930 ( diff = 0.076763 ) train-gini = 0.941386 val-gini = 0.787860\n",
      "   12 | 01m32s |    0.78786 |             0.7067 |   10.6987 |           1.9001 |      5.5683 |             2.2659 |      0.9573 | \n",
      " Stopped after 41 iterations with train-auc = 0.951014 val-auc = 0.846970 ( diff = 0.104044 ) train-gini = 0.902028 val-gini = 0.693940\n",
      "   13 | 00m26s |    0.69394 |             0.5259 |    7.7623 |           4.4071 |      6.4331 |            18.0410 |      0.9019 | \n",
      " Stopped after 258 iterations with train-auc = 0.904405 val-auc = 0.850018 ( diff = 0.054387 ) train-gini = 0.808810 val-gini = 0.700035\n",
      "   14 | 01m25s |    0.70004 |             0.5915 |   17.7707 |           7.4542 |      7.2424 |             0.7782 |      0.5145 | \n",
      " Stopped after 37 iterations with train-auc = 0.896145 val-auc = 0.808085 ( diff = 0.088060 ) train-gini = 0.792291 val-gini = 0.616170\n",
      "   15 | 00m32s |    0.61617 |             0.8189 |   12.6552 |           5.8479 |     10.3610 |            10.9184 |      0.5049 | \n",
      " Stopped after 260 iterations with train-auc = 0.886105 val-auc = 0.813215 ( diff = 0.072890 ) train-gini = 0.772210 val-gini = 0.626430\n",
      "   16 | 00m54s |    0.62643 |             0.8290 |   15.0650 |           0.7612 |      3.8251 |             4.6342 |      0.9526 | \n",
      " Stopped after 28 iterations with train-auc = 0.933293 val-auc = 0.863375 ( diff = 0.069918 ) train-gini = 0.866586 val-gini = 0.726750\n",
      "   17 | 00m23s |    0.72675 |             0.6573 |    1.9772 |           9.3322 |      4.4851 |            12.9423 |      0.9056 | \n",
      " Stopped after 19 iterations with train-auc = 0.859047 val-auc = 0.771615 ( diff = 0.087432 ) train-gini = 0.718094 val-gini = 0.543230\n",
      "   18 | 00m14s |    0.54323 |             0.4930 |    8.4158 |           2.3122 |     11.8589 |            15.7645 |      0.4669 | \n",
      " Stopped after 13 iterations with train-auc = 0.923020 val-auc = 0.844922 ( diff = 0.078098 ) train-gini = 0.846040 val-gini = 0.689844\n",
      "   19 | 00m35s |    0.68984 |             0.7312 |   10.7945 |           4.3916 |      9.9734 |             5.1898 |      0.5536 | \n",
      " Stopped after 43 iterations with train-auc = 0.961581 val-auc = 0.844480 ( diff = 0.117101 ) train-gini = 0.923163 val-gini = 0.688960\n",
      "   20 | 00m25s |    0.68896 |             0.6081 |    2.4177 |           6.2378 |      5.0118 |            14.2649 |      0.7156 | \n",
      " Stopped after 28 iterations with train-auc = 0.916459 val-auc = 0.836710 ( diff = 0.079749 ) train-gini = 0.832918 val-gini = 0.673420\n",
      "   21 | 00m32s |    0.67342 |             0.9607 |    0.0757 |           3.9900 |      4.9966 |            18.0176 |      0.8056 | \n",
      " Stopped after 523 iterations with train-auc = 0.932020 val-auc = 0.869490 ( diff = 0.062530 ) train-gini = 0.864040 val-gini = 0.738980\n",
      "   22 | 02m32s |    0.73898 |             0.4991 |   16.4500 |           7.8893 |     10.3253 |             6.2219 |      0.6919 | \n",
      " Stopped after 17 iterations with train-auc = 0.909190 val-auc = 0.789175 ( diff = 0.120015 ) train-gini = 0.818381 val-gini = 0.578350\n",
      "   23 | 00m15s |    0.57835 |             0.4135 |    1.7816 |           5.5938 |     10.6030 |            10.5800 |      0.4969 | \n",
      " Stopped after 17 iterations with train-auc = 0.927374 val-auc = 0.820055 ( diff = 0.107319 ) train-gini = 0.854748 val-gini = 0.640110\n",
      "   24 | 00m35s |    0.64011 |             0.9777 |    5.1249 |           4.7350 |     11.7633 |             9.2918 |      0.5246 | \n",
      " Stopped after 82 iterations with train-auc = 0.942054 val-auc = 0.886015 ( diff = 0.056039 ) train-gini = 0.884108 val-gini = 0.772030\n",
      "   25 | 00m56s |    0.77203 |             0.9080 |   14.0146 |           6.2798 |      5.0542 |             2.9424 |      0.7585 | \n",
      " Stopped after 40 iterations with train-auc = 0.892315 val-auc = 0.811345 ( diff = 0.080970 ) train-gini = 0.784630 val-gini = 0.622690\n",
      "   26 | 00m20s |    0.62269 |             0.6547 |    2.7248 |           6.5767 |      3.3091 |            15.5224 |      0.9572 | \n",
      " Stopped after 493 iterations with train-auc = 0.907013 val-auc = 0.818990 ( diff = 0.088023 ) train-gini = 0.814026 val-gini = 0.637980\n",
      "   27 | 01m59s |    0.63798 |             0.9721 |   15.4411 |           1.1435 |      3.6360 |             8.6713 |      0.6790 | \n",
      " Stopped after 734 iterations with train-auc = 0.913548 val-auc = 0.854065 ( diff = 0.059483 ) train-gini = 0.827096 val-gini = 0.708130\n",
      "   28 | 02m24s |    0.70813 |             0.4688 |   17.4965 |           1.4269 |      6.3973 |             8.8107 |      0.6900 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   subsample | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Stopped after 29 iterations with train-auc = 0.837072 val-auc = 0.800070 ( diff = 0.037002 ) train-gini = 0.674144 val-gini = 0.600140\n",
      "   29 | 00m29s |    0.60014 |             0.4000 |   20.0000 |          10.0000 |      3.0000 |            20.0000 |      1.0000 | \n",
      " Stopped after 21 iterations with train-auc = 0.829606 val-auc = 0.793770 ( diff = 0.035836 ) train-gini = 0.659212 val-gini = 0.587540\n",
      "   30 | 00m30s |    0.58754 |             1.0000 |   20.0000 |           0.0000 |      3.0000 |            20.0000 |      1.0000 | \n",
      " Stopped after 673 iterations with train-auc = 1.000000 val-auc = 0.888175 ( diff = 0.111825 ) train-gini = 1.000000 val-gini = 0.776350\n",
      "   31 | 12m24s |    0.77635 |             1.0000 |    0.0010 |          10.0000 |     12.0000 |             0.0000 |      1.0000 | \n",
      " Stopped after 24 iterations with train-auc = 0.881325 val-auc = 0.846532 ( diff = 0.034793 ) train-gini = 0.762651 val-gini = 0.693065\n",
      "   32 | 01m10s |    0.69306 |             1.0000 |   20.0000 |          10.0000 |     12.0000 |            20.0000 |      1.0000 | \n",
      " Stopped after 23 iterations with train-auc = 0.915169 val-auc = 0.870925 ( diff = 0.044244 ) train-gini = 0.830338 val-gini = 0.741850\n",
      "   33 | 01m40s |    0.74185 |             1.0000 |   20.0000 |           0.0000 |     12.0000 |             0.0000 |      1.0000 | \n",
      " Stopped after 24 iterations with train-auc = 0.881325 val-auc = 0.846532 ( diff = 0.034793 ) train-gini = 0.762651 val-gini = 0.693065\n",
      "   34 | 00m59s |    0.69306 |             1.0000 |   20.0000 |           0.0000 |     12.0000 |            20.0000 |      1.0000 | \n",
      " Stopped after 25 iterations with train-auc = 0.837265 val-auc = 0.795810 ( diff = 0.041454 ) train-gini = 0.674529 val-gini = 0.591621\n",
      "   35 | 00m45s |    0.59162 |             1.0000 |   20.0000 |          10.0000 |      3.0000 |             7.9707 |      1.0000 | \n",
      " Stopped after 27 iterations with train-auc = 0.884537 val-auc = 0.783390 ( diff = 0.101147 ) train-gini = 0.769073 val-gini = 0.566780\n",
      "   36 | 00m33s |    0.56678 |             1.0000 |    6.3368 |          10.0000 |      3.0000 |             0.0000 |      0.4000 | \n",
      " Stopped after 673 iterations with train-auc = 1.000000 val-auc = 0.888175 ( diff = 0.111825 ) train-gini = 1.000000 val-gini = 0.776350\n",
      "   37 | 09m30s |    0.77635 |             1.0000 |    0.0010 |           0.0000 |     12.0000 |             0.0000 |      1.0000 | \n",
      " Stopped after 26 iterations with train-auc = 0.934252 val-auc = 0.855440 ( diff = 0.078812 ) train-gini = 0.868504 val-gini = 0.710880\n",
      "   38 | 00m53s |    0.71088 |             1.0000 |    0.0010 |           0.0000 |     12.0000 |            20.0000 |      1.0000 | \n",
      " Stopped after 23 iterations with train-auc = 0.915169 val-auc = 0.870925 ( diff = 0.044244 ) train-gini = 0.830338 val-gini = 0.741850\n",
      "   39 | 02m04s |    0.74185 |             1.0000 |   20.0000 |          10.0000 |     12.0000 |             0.0000 |      1.0000 | \n",
      " Stopped after 26 iterations with train-auc = 0.934252 val-auc = 0.855440 ( diff = 0.078812 ) train-gini = 0.868504 val-gini = 0.710880\n",
      "   40 | 01m01s |    0.71088 |             1.0000 |    0.0010 |          10.0000 |     12.0000 |            20.0000 |      1.0000 | \n",
      " Stopped after 29 iterations with train-auc = 0.966784 val-auc = 0.890135 ( diff = 0.076649 ) train-gini = 0.933568 val-gini = 0.780270\n",
      "   41 | 02m21s |    0.78027 |             1.0000 |   10.4575 |          10.0000 |     12.0000 |             0.0000 |      1.0000 | \n",
      " Stopped after 21 iterations with train-auc = 0.901827 val-auc = 0.862215 ( diff = 0.039612 ) train-gini = 0.803655 val-gini = 0.724430\n",
      "   42 | 01m09s |    0.72443 |             1.0000 |   20.0000 |           0.0000 |     12.0000 |            10.4685 |      1.0000 | \n",
      " Stopped after 408 iterations with train-auc = 0.840733 val-auc = 0.791035 ( diff = 0.049698 ) train-gini = 0.681466 val-gini = 0.582070\n",
      "   43 | 01m23s |    0.58207 |             1.0000 |   20.0000 |           0.0000 |      3.0000 |             0.0000 |      0.4000 | \n",
      " Stopped after 17 iterations with train-auc = 0.799229 val-auc = 0.741945 ( diff = 0.057284 ) train-gini = 0.598458 val-gini = 0.483890\n",
      "   44 | 00m30s |    0.48389 |             1.0000 |    0.0010 |          10.0000 |      3.0000 |            20.0000 |      0.4000 | \n",
      " Stopped after 17 iterations with train-auc = 0.798728 val-auc = 0.742125 ( diff = 0.056604 ) train-gini = 0.597457 val-gini = 0.484250\n",
      "   45 | 00m30s |    0.48425 |             1.0000 |    7.0437 |           0.0000 |      3.0000 |            20.0000 |      0.4000 | \n",
      " Stopped after 404 iterations with train-auc = 0.840608 val-auc = 0.791635 ( diff = 0.048973 ) train-gini = 0.681216 val-gini = 0.583270\n",
      "   46 | 02m11s |    0.58327 |             1.0000 |   20.0000 |          10.0000 |     12.0000 |            12.0221 |      0.4000 | \n",
      " Stopped after 46 iterations with train-auc = 0.913841 val-auc = 0.810960 ( diff = 0.102881 ) train-gini = 0.827682 val-gini = 0.621920\n",
      "   47 | 00m51s |    0.62192 |             1.0000 |    0.0010 |          10.0000 |      3.0000 |             5.2644 |      1.0000 | \n",
      " Stopped after 190 iterations with train-auc = 0.849855 val-auc = 0.804260 ( diff = 0.045595 ) train-gini = 0.699710 val-gini = 0.608520\n",
      "   48 | 00m45s |    0.60852 |             0.4000 |   20.0000 |          10.0000 |      3.0000 |             0.0000 |      1.0000 | \n",
      " Stopped after 20 iterations with train-auc = 0.893070 val-auc = 0.856165 ( diff = 0.036906 ) train-gini = 0.786141 val-gini = 0.712330\n",
      "   49 | 01m10s |    0.71233 |             1.0000 |   20.0000 |           4.9528 |      7.3750 |            16.5330 |      1.0000 | \n",
      " Stopped after 29 iterations with train-auc = 0.969613 val-auc = 0.886665 ( diff = 0.082948 ) train-gini = 0.939225 val-gini = 0.773330\n",
      "   50 | 00m43s |    0.77333 |             0.4000 |    8.4478 |          10.0000 |      6.7298 |             6.5701 |      1.0000 | \n",
      " Stopped after 35 iterations with train-auc = 0.858188 val-auc = 0.799478 ( diff = 0.058711 ) train-gini = 0.716376 val-gini = 0.598955\n",
      "   51 | 00m48s |    0.59896 |             1.0000 |   12.4926 |          10.0000 |      3.0000 |            20.0000 |      1.0000 | \n",
      " Stopped after 41 iterations with train-auc = 0.997708 val-auc = 0.879810 ( diff = 0.117898 ) train-gini = 0.995416 val-gini = 0.759620\n",
      "   52 | 01m35s |    0.75962 |             1.0000 |    0.0010 |          10.0000 |     12.0000 |             7.3792 |      1.0000 | \n",
      " Stopped after 20 iterations with train-auc = 0.908432 val-auc = 0.864950 ( diff = 0.043482 ) train-gini = 0.816864 val-gini = 0.729900\n",
      "   53 | 00m56s |    0.72990 |             1.0000 |   14.3770 |           0.0000 |      7.7809 |            16.6304 |      1.0000 | \n",
      "CPU times: user 1h 14min 13s, sys: 23.7 s, total: 1h 14min 37s\n",
      "Wall time: 1h 9min 33s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# # Define the log file. If you repeat this run, new output will be added to it\n",
    "# import warnings\n",
    "\n",
    "# log_file = open('Opleai-AUC-5fold-XGB-run-01-v1-full.log', 'a')\n",
    "# AUCbest = -1.\n",
    "# ITERbest = 0\n",
    "\n",
    "# print('-'*30)\n",
    "# print('-'*30, file=log_file)\n",
    "# log_file.flush()\n",
    "\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.filterwarnings('ignore')\n",
    "#     XGB_BO.maximize(init_points=10, n_iter=25, acq='ucb', kappa=10)\n",
    "# # XGB_BO.maximize(init_points=10, n_iter=50, acq='ucb', kappa=10)\n",
    "# # XGB_BO.maximize(init_points=10, n_iter=50, acq='ucb', kappa=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results\n",
      "Maximum XGBOOST value: 0.789440\n",
      "Best XGBOOST parameters:  {'max_depth': 8.0, 'gamma': 8.0, 'min_child_weight': 0.20000000000000001, 'max_delta_step': 2.0, 'subsample': 0.80000000000000004, 'colsample_bytree': 0.80000000000000004}\n"
     ]
    }
   ],
   "source": [
    "print('Final Results')\n",
    "print('Maximum XGBOOST value: %f' % XGB_BO.res['max']['max_val'])\n",
    "print('Best XGBOOST parameters: ', XGB_BO.res['max']['max_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=8, learning_rate=0.05, max_delta_step=2, max_depth=8,\n",
       "       min_child_weight=0.2, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=3, silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 fold cross validation is more accurate than using a single validation set\n",
    "path1 = 'obtrain-ml.csv'\n",
    "df = pd.read_csv(path1, header=None)\n",
    "y = df[559]\n",
    "X = df.drop(559,axis=1)\n",
    "y = y.replace([-1.0], 0)\n",
    "\n",
    "# set the seed of random number generator, which is useful for creating simulations \n",
    "# or random objects that can be reproduced.\n",
    "import random\n",
    "SEED=3\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "cv_folds = 5\n",
    "early_stopping_rounds = 400\n",
    "model=xgb.XGBClassifier(seed = SEED)\n",
    "xgb_param = model.get_xgb_params()\n",
    "model.set_params(learning_rate=0.05, max_depth=8, gamma=8, min_child_weight=0.2, max_delta_step=2, \n",
    "                 subsample=0.8, colsample_bytree=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>gini</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.069344</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.403141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Extra Tree</td>\n",
       "      <td>0.077184</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.507726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.051136</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.524793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.09472</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.553971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.11504</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.561475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.122944</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.563786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.150816</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.579592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.182272</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.599190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.176448</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.342592</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.665272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.486144</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.746988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoostClassifier</td>\n",
       "      <td>0.549728</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.771717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BayesOPtiTuned xgb</td>\n",
       "      <td>0.5968</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.796813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xgb2</td>\n",
       "      <td>0.649952</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.816000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       clf      gini precision accuracy        f1\n",
       "2     KNeighborsClassifier  0.069344     0.308    0.544  0.403141\n",
       "11              Extra Tree  0.077184      0.46    0.554  0.507726\n",
       "6            SGDClassifier  0.051136     0.508     0.54  0.524793\n",
       "5                LinearSVC   0.09472     0.544    0.562  0.553971\n",
       "0       LogisticRegression   0.11504     0.548    0.572  0.561475\n",
       "4               Perceptron  0.122944     0.548    0.576  0.563786\n",
       "3               GaussianNB  0.150816     0.568    0.588  0.579592\n",
       "10                AdaBoost  0.182272     0.592    0.604  0.599190\n",
       "1                      SVC  0.176448     0.604    0.604  0.604000\n",
       "8   RandomForestClassifier  0.342592     0.636     0.68  0.665272\n",
       "7   DecisionTreeClassifier  0.486144     0.744    0.748  0.746988\n",
       "9        XGBoostClassifier  0.549728     0.764    0.774  0.771717\n",
       "13      BayesOPtiTuned xgb    0.5968       0.8    0.796  0.796813\n",
       "12                    xgb2  0.649952     0.816    0.816  0.816000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb10=model\n",
    "xgb10.fit(X_train,y_train)\n",
    "ypred = xgb10.predict(X_test)\n",
    "gini_ = gini_normalized(y_test,ypred)\n",
    "precision_ = precision_score(ypred, y_test)\n",
    "accuracy_ = accuracy_score(ypred,y_test)\n",
    "f1_ = f1_score(ypred,y_test)\n",
    "# print('%s classifier: gini = %.4f, precision = %.4f, accuracy = %.4f, f1 score = %.4f' \n",
    "#       %(name, gini_, precision_, accuracy_, f1_))\n",
    "df10 = pd.DataFrame([['BayesOPtiTuned xgb', gini_, precision_, accuracy_, f1_]], columns=['clf', 'gini', 'precision', 'accuracy', 'f1'])\n",
    "res2_score = res2_score.append(df10, ignore_index=True)\n",
    "res2_score.sort_values('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>gini</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.069344</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.403141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Extra Tree</td>\n",
       "      <td>0.077184</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.507726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.051136</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.524793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.09472</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.553971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.11504</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.561475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.122944</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.563786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.150816</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.579592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.182272</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.599190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.176448</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.342592</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.665272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.486144</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.746988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoostClassifier</td>\n",
       "      <td>0.549728</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.771717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BayesOPtiTuned xgb</td>\n",
       "      <td>0.5968</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.796813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xgb2</td>\n",
       "      <td>0.649952</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tuned xgb</td>\n",
       "      <td>0.65824</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.828685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       clf      gini precision accuracy        f1\n",
       "2     KNeighborsClassifier  0.069344     0.308    0.544  0.403141\n",
       "11              Extra Tree  0.077184      0.46    0.554  0.507726\n",
       "6            SGDClassifier  0.051136     0.508     0.54  0.524793\n",
       "5                LinearSVC   0.09472     0.544    0.562  0.553971\n",
       "0       LogisticRegression   0.11504     0.548    0.572  0.561475\n",
       "4               Perceptron  0.122944     0.548    0.576  0.563786\n",
       "3               GaussianNB  0.150816     0.568    0.588  0.579592\n",
       "10                AdaBoost  0.182272     0.592    0.604  0.599190\n",
       "1                      SVC  0.176448     0.604    0.604  0.604000\n",
       "8   RandomForestClassifier  0.342592     0.636     0.68  0.665272\n",
       "7   DecisionTreeClassifier  0.486144     0.744    0.748  0.746988\n",
       "9        XGBoostClassifier  0.549728     0.764    0.774  0.771717\n",
       "13      BayesOPtiTuned xgb    0.5968       0.8    0.796  0.796813\n",
       "12                    xgb2  0.649952     0.816    0.816  0.816000\n",
       "14               Tuned xgb   0.65824     0.832    0.828  0.828685"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb11=xgb.XGBClassifier(n_estimators=21, max_depth = 5, min_child_weight = 4, \n",
    "                        gamma = 0.5, colsample_bytree=0.6, subsample=0.9, reg_lambda=0.017, \n",
    "                        reg_alpha=0.007, learning_rate=0.0445, silent=1, nthread = 4)\n",
    "xgb11.fit(X_train,y_train)\n",
    "ypred = xgb11.predict(X_test)\n",
    "gini_ = gini_normalized(y_test,ypred)\n",
    "precision_ = precision_score(ypred, y_test)\n",
    "accuracy_ = accuracy_score(ypred,y_test)\n",
    "f1_ = f1_score(ypred,y_test)\n",
    "df11 = pd.DataFrame([['Tuned xgb', gini_, precision_, accuracy_, f1_]], columns=['clf', 'gini', 'precision', 'accuracy', 'f1'])\n",
    "res2_score = res2_score.append(df11, ignore_index=True)\n",
    "res2_score.sort_values('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 99.6,  99.7,  99.8,  99.9, 100. ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAF1CAYAAADm2uMAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1210d9d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find the n_compoents\n",
    "from sklearn.decomposition import PCA\n",
    "covar_matrix = PCA(n_components = 456)\n",
    "covar_matrix.fit(X_train)\n",
    "variance = covar_matrix.explained_variance_ratio_ #calculate variance ratios\n",
    "\n",
    "var=np.cumsum(np.round(covar_matrix.explained_variance_ratio_, decimals=3)*100)\n",
    "\n",
    "plt.ylabel('% Variance Explained')\n",
    "plt.xlabel('# of Features')\n",
    "plt.title('PCA Analysis')\n",
    "plt.ylim(0,100.5)\n",
    "plt.style.context('seaborn-whitegrid')\n",
    "\n",
    "plt.plot(var)\n",
    "var[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the classifiers used in this problem: \n",
      " 0         LogisticRegression\n",
      "1                        SVC\n",
      "2       KNeighborsClassifier\n",
      "3                 GaussianNB\n",
      "4                 Perceptron\n",
      "5                  LinearSVC\n",
      "6              SGDClassifier\n",
      "7     DecisionTreeClassifier\n",
      "8     RandomForestClassifier\n",
      "9          XGBoostClassifier\n",
      "10                  AdaBoost\n",
      "11                Extra Tree\n",
      "12                      xgb2\n",
      "13        BayesOPtiTuned xgb\n",
      "14                 Tuned xgb\n",
      "15             Tuned xgb_pca\n",
      "Name: clf, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>gini</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.069344</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.403141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Extra Tree</td>\n",
       "      <td>0.077184</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.507726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.051136</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.524793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.09472</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.553971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.11504</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.561475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.122944</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.563786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tuned xgb_pca</td>\n",
       "      <td>0.222624</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.577273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.150816</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.579592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.182272</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.599190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.176448</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.342592</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.665272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.486144</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.746988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoostClassifier</td>\n",
       "      <td>0.549728</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.771717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BayesOPtiTuned xgb</td>\n",
       "      <td>0.5968</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.796813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xgb2</td>\n",
       "      <td>0.649952</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tuned xgb</td>\n",
       "      <td>0.65824</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.828685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       clf      gini precision accuracy        f1\n",
       "2     KNeighborsClassifier  0.069344     0.308    0.544  0.403141\n",
       "11              Extra Tree  0.077184      0.46    0.554  0.507726\n",
       "6            SGDClassifier  0.051136     0.508     0.54  0.524793\n",
       "5                LinearSVC   0.09472     0.544    0.562  0.553971\n",
       "0       LogisticRegression   0.11504     0.548    0.572  0.561475\n",
       "4               Perceptron  0.122944     0.548    0.576  0.563786\n",
       "15           Tuned xgb_pca  0.222624     0.508    0.628  0.577273\n",
       "3               GaussianNB  0.150816     0.568    0.588  0.579592\n",
       "10                AdaBoost  0.182272     0.592    0.604  0.599190\n",
       "1                      SVC  0.176448     0.604    0.604  0.604000\n",
       "8   RandomForestClassifier  0.342592     0.636     0.68  0.665272\n",
       "7   DecisionTreeClassifier  0.486144     0.744    0.748  0.746988\n",
       "9        XGBoostClassifier  0.549728     0.764    0.774  0.771717\n",
       "13      BayesOPtiTuned xgb    0.5968       0.8    0.796  0.796813\n",
       "12                    xgb2  0.649952     0.816    0.816  0.816000\n",
       "14               Tuned xgb   0.65824     0.832    0.828  0.828685"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tuned xgbclf on data after pca \n",
    "n_components = 456\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "          whiten=True).fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "xgb12=xgb.XGBClassifier(n_estimators=21, max_depth = 5, min_child_weight = 4, \n",
    "                        gamma = 0.5, colsample_bytree=0.6, subsample=0.9, reg_lambda=0.017, \n",
    "                        reg_alpha=0.007, learning_rate=0.0445, silent=1, nthread = 4)\n",
    "xgb12.fit(X_train_pca,y_train)\n",
    "ypred = xgb12.predict(X_test_pca)\n",
    "gini_ = gini_normalized(y_test,ypred)\n",
    "precision_ = precision_score(ypred, y_test)\n",
    "accuracy_ = accuracy_score(ypred,y_test)\n",
    "f1_ = f1_score(ypred,y_test)\n",
    "df12 = pd.DataFrame([['Tuned xgb_pca', gini_, precision_, accuracy_, f1_]], columns=['clf', 'gini', 'precision', 'accuracy', 'f1'])\n",
    "res2_score = res2_score.append(df12, ignore_index=True)\n",
    "print(\"All the classifiers used in this problem:\", '\\n',res2_score.clf)\n",
    "res2_score.sort_values('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
